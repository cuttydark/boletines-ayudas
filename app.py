import streamlit as st
import requests
import feedparser
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import re
import time
import json
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from openai import OpenAI

st.set_page_config(page_title="B√∫squeda Ayudas BOJA/BOE con IA", layout="wide", page_icon="üîç")

# ============= CONFIGURACI√ìN DE SESI√ìN MEJORADA =============

def crear_session():
    """Crea una sesi√≥n HTTP con retry autom√°tico y User-Agent completo"""
    session = requests.Session()
    
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "es-ES,es;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate",
        "Connection": "keep-alive",
    })
    
    return session

session = crear_session()

# ============= FUNCIONES DE IA CON OPENAI =============

def resumir_con_openai(texto, api_key, modelo="gpt-4o-mini", max_palabras=150):
    """Genera un resumen estructurado usando OpenAI API"""
    try:
        client = OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model=modelo,
            messages=[
                {
                    "role": "system",
                    "content": """Eres un experto en analizar ayudas y subvenciones p√∫blicas espa√±olas del BOE y BOJA. 
Extrae informaci√≥n clave de forma estructurada y precisa en espa√±ol."""
                },
                {
                    "role": "user",
                    "content": f"""Analiza este documento oficial y proporciona SOLO un JSON con esta estructura exacta:

{{
  "tipo": "tipo de documento (ej: Subvenci√≥n, Convocatoria, Resoluci√≥n, Bases reguladoras)",
  "beneficiarios": "qui√©n puede solicitarla (ej: PYMES, aut√≥nomos, entidades locales)",
  "cuantia": "importe o porcentaje disponible",
  "plazo": "fecha l√≠mite de solicitud o duraci√≥n",
  "resumen": "descripci√≥n breve en m√°ximo {max_palabras} palabras"
}}

DOCUMENTO:
{texto[:8000]}

Responde SOLO con el JSON, sin texto adicional."""
                }
            ],
            temperature=0.2,
            max_tokens=600,
            response_format={"type": "json_object"}
        )
        
        resultado = json.loads(response.choices[0].message.content)
        return resultado
    
    except Exception as e:
        return {
            "tipo": "Error al procesar",
            "beneficiarios": "No disponible",
            "cuantia": "No disponible",
            "plazo": "No disponible",
            "resumen": f"Error al generar resumen: {str(e)[:100]}",
            "error": str(e)
        }

def busqueda_inteligente_openai(consulta_usuario, api_key, modelo="gpt-4o-mini"):
    """Convierte una consulta en lenguaje natural a palabras clave espec√≠ficas"""
    try:
        client = OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model=modelo,
            messages=[
                {
                    "role": "system",
                    "content": "Eres un experto en ayudas p√∫blicas espa√±olas. Convierte consultas naturales en palabras clave para b√∫squeda en BOE/BOJA."
                },
                {
                    "role": "user",
                    "content": f"""Un usuario busca: "{consulta_usuario}"

Extrae las palabras clave M√ÅS RELEVANTES para buscar en el BOE/BOJA.
Responde SOLO con las palabras clave separadas por comas, sin explicaciones.

Ejemplos:
- "ayudas para abrir un restaurante" ‚Üí "hosteler√≠a, restauraci√≥n, pyme, emprendimiento"
- "subvenciones turismo rural Andaluc√≠a" ‚Üí "turismo rural, alojamiento, feder, andaluc√≠a"
- "financiaci√≥n startups tecnol√≥gicas" ‚Üí "startup, innovaci√≥n, tecnolog√≠a, emprendimiento, I+D"

Palabras clave:"""
                }
            ],
            temperature=0.3,
            max_tokens=100
        )
        
        palabras = response.choices[0].message.content.strip()
        return palabras
    
    except Exception as e:
        st.error(f"Error en b√∫squeda inteligente: {e}")
        return consulta_usuario

def analizar_relevancia_openai(titulo, resumen, palabras_objetivo, api_key, modelo="gpt-4o-mini"):
    """Usa IA para determinar si una ayuda es relevante seg√∫n criterios del usuario"""
    try:
        client = OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model=modelo,
            messages=[
                {
                    "role": "system",
                    "content": "Eres un experto en ayudas p√∫blicas espa√±olas. Eval√∫a la relevancia de documentos."
                },
                {
                    "role": "user",
                    "content": f"""Analiza si esta ayuda/subvenci√≥n es relevante para alguien interesado en: {', '.join(palabras_objetivo)}

T√çTULO: {titulo}
RESUMEN: {resumen[:500]}

Responde SOLO con un n√∫mero del 0 al 10 donde:
- 0-3: No relevante
- 4-6: Moderadamente relevante
- 7-10: Muy relevante

N√∫mero:"""
                }
            ],
            temperature=0.2,
            max_tokens=10
        )
        
        texto = response.choices[0].message.content.strip()
        numeros = re.findall(r'\d+', texto)
        if numeros:
            return int(numeros[0])
        return 5
    
    except:
        return 5

# ============= FUNCIONES DE B√öSQUEDA =============

def extraer_contenido_completo(url, max_intentos=2):
    """Extrae el texto completo de una p√°gina"""
    for intento in range(max_intentos):
        try:
            response = session.get(url, timeout=20)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            for element in soup(["script", "style", "nav", "header", "footer", "iframe"]):
                element.decompose()
            
            contenido = soup.get_text(separator=' ', strip=True)
            time.sleep(0.5)
            
            return contenido
            
        except requests.exceptions.Timeout:
            if intento < max_intentos - 1:
                st.warning(f"‚è±Ô∏è Timeout en {url} (intento {intento + 1}/{max_intentos})")
        except requests.exceptions.HTTPError as e:
            st.warning(f"‚ùå Error HTTP {e.response.status_code} en {url}")
            break
        except requests.exceptions.RequestException as e:
            if intento < max_intentos - 1:
                st.warning(f"‚ö†Ô∏è Error de conexi√≥n: {str(e)[:100]}")
        except Exception as e:
            st.error(f"üî¥ Error inesperado: {str(e)[:100]}")
    
    return ""

def buscar_boja_feed(contenido_completo=False):
    """Busca en el feed principal de BOJA con filtrado mejorado"""
    resultados = []
    url = "https://www.juntadeandalucia.es/boja/distribucion/boja.xml"
    
    try:
        response = session.get(url, timeout=20)
        response.raise_for_status()
        
        feed = feedparser.parse(response.content)
        
        for entry in feed.entries:
            titulo = entry.get('title', '')
            resumen = BeautifulSoup(entry.get('summary', ''), 'html.parser').get_text()
            enlace = entry.get('link', '')
            
            # ============= FILTRO MEJORADO =============
            # Excluir enlaces a p√°ginas institucionales gen√©ricas
            urls_excluir = [
                '/temas/',
                '/organismos/',
                '/servicios/',
                'juntadeandalucia.es/temas',
                'juntadeandalucia.es/organismos'
            ]
            
            # Verificar si el enlace es a un documento oficial del BOJA
            if any(excluir in enlace for excluir in urls_excluir):
                continue  # Saltar este resultado
            
            # Verificar que el enlace contenga un n√∫mero de BOJA
            if '/boja/' not in enlace and '/eboja/' not in enlace:
                continue  # Solo aceptar enlaces a boletines oficiales
            # ============= FIN FILTRO =============
            
            fecha_str = entry.get('published', entry.get('updated', ''))
            fecha = pd.to_datetime(fecha_str, errors='coerce', utc=True)
            if pd.notna(fecha):
                fecha = fecha.tz_localize(None)
            
            texto_completo = ""
            if contenido_completo and enlace:
                texto_completo = extraer_contenido_completo(enlace)
            
            resultados.append({
                'Bolet√≠n': 'BOJA',
                'T√≠tulo': titulo,
                'Resumen': resumen[:300],
                'Contenido_Completo': texto_completo,
                'Enlace': enlace,
                'Fecha': fecha
            })
            
    except requests.exceptions.RequestException as e:
        st.error(f"Error al buscar en BOJA: {e}")
    except Exception as e:
        st.error(f"Error inesperado en BOJA: {e}")
    
    return resultados

def buscar_boe_rss(contenido_completo=False):
    """Busca en el RSS del BOE"""
    resultados = []
    url = "https://www.boe.es/rss/boe.php"
    
    try:
        response = session.get(url, timeout=20)
        response.raise_for_status()
        
        feed = feedparser.parse(response.content)
        
        for entry in feed.entries:
            titulo = entry.get('title', '')
            resumen = BeautifulSoup(entry.get('summary', ''), 'html.parser').get_text()
            enlace = entry.get('link', '')
            
            fecha_str = entry.get('published', entry.get('updated', ''))
            fecha = pd.to_datetime(fecha_str, errors='coerce', utc=True)
            if pd.notna(fecha):
                fecha = fecha.tz_localize(None)
            
            texto_completo = ""
            if contenido_completo and enlace:
                texto_completo = extraer_contenido_completo(enlace)
            
            resultados.append({
                'Bolet√≠n': 'BOE',
                'T√≠tulo': titulo,
                'Resumen': resumen[:300],
                'Contenido_Completo': texto_completo,
                'Enlace': enlace,
                'Fecha': fecha
            })
            
    except requests.exceptions.RequestException as e:
        st.error(f"Error al buscar en BOE RSS: {e}")
    except Exception as e:
        st.error(f"Error inesperado en BOE RSS: {e}")
    
    return resultados

def buscar_boe_historico_api(fecha_inicio, fecha_fin, contenido_completo=False):
    """Busca en el BOE por rango de fechas usando la API oficial"""
    resultados = []
    fecha_actual = fecha_inicio
    
    progress_text = st.empty()
    progress_bar = st.progress(0)
    
    total_dias = (fecha_fin - fecha_actual).days + 1
    dia_actual = 0
    
    while fecha_actual <= fecha_fin:
        progreso = dia_actual / total_dias
        progress_bar.progress(progreso)
        progress_text.text(f"Consultando BOE del {fecha_actual.strftime('%d/%m/%Y')} ({dia_actual+1}/{total_dias})")
        
        fecha_str = fecha_actual.strftime("%Y%m%d")
        url = f"https://www.boe.es/datosabiertos/api/boe/sumario/{fecha_str}"
        
        try:
            response = session.get(url, headers={"Accept": "application/json"}, timeout=20)
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get("status", {}).get("code") == "200":
                    sumario = data.get("data", {}).get("sumario", {})
                    
                    for diario in sumario.get("diario", []):
                        for seccion in diario.get("seccion", []):
                            for departamento in seccion.get("departamento", []):
                                for epigrafe in departamento.get("epigrafe", []):
                                    items = epigrafe.get("item", [])
                                    if isinstance(items, dict):
                                        items = [items]
                                    
                                    for item in items:
                                        titulo = item.get("titulo", "")
                                        enlace = item.get("url_html", "")
                                        
                                        texto_completo = ""
                                        if contenido_completo and enlace:
                                            texto_completo = extraer_contenido_completo(enlace)
                                        
                                        resultados.append({
                                            'Bolet√≠n': 'BOE',
                                            'T√≠tulo': titulo,
                                            'Resumen': f"Secci√≥n: {seccion.get('nombre', '')} - {departamento.get('nombre', '')}",
                                            'Contenido_Completo': texto_completo,
                                            'Enlace': enlace,
                                            'Fecha': pd.to_datetime(fecha_actual)
                                        })
                                
                                items_directos = departamento.get("item", [])
                                if isinstance(items_directos, dict):
                                    items_directos = [items_directos]
                                
                                for item in items_directos:
                                    titulo = item.get("titulo", "")
                                    enlace = item.get("url_html", "")
                                    
                                    texto_completo = ""
                                    if contenido_completo and enlace:
                                        texto_completo = extraer_contenido_completo(enlace)
                                    
                                    resultados.append({
                                        'Bolet√≠n': 'BOE',
                                        'T√≠tulo': titulo,
                                        'Resumen': f"Secci√≥n: {seccion.get('nombre', '')} - {departamento.get('nombre', '')}",
                                        'Contenido_Completo': texto_completo,
                                        'Enlace': enlace,
                                        'Fecha': pd.to_datetime(fecha_actual)
                                    })
            
            elif response.status_code != 404:
                st.warning(f"‚ö†Ô∏è Error {response.status_code} al consultar BOE del {fecha_actual.strftime('%d/%m/%Y')}")
            
            time.sleep(0.3)
            
        except requests.exceptions.RequestException as e:
            st.warning(f"Error de conexi√≥n para fecha {fecha_actual.strftime('%d/%m/%Y')}: {str(e)[:100]}")
        except Exception as e:
            st.error(f"Error procesando BOE del {fecha_actual.strftime('%d/%m/%Y')}: {str(e)[:100]}")
        
        fecha_actual += timedelta(days=1)
        dia_actual += 1
    
    progress_bar.empty()
    progress_text.empty()
    
    return resultados

# ============= NUEVA FUNCI√ìN MEJORADA PARA BOJA HIST√ìRICO =============

def buscar_boja_historico(fecha_inicio, fecha_fin, contenido_completo=False):
    """Busca en BOJA hist√≥rico usando el feed RSS y filtrando por fechas"""
    
    st.info("üîç Buscando en BOJA mediante feed RSS hist√≥rico...")
    
    # Primero, obtener todos los resultados del feed RSS
    resultados_feed = buscar_boja_feed(contenido_completo=False)
    
    if not resultados_feed:
        st.warning("‚ö†Ô∏è No se pudieron obtener datos del feed RSS")
        return []
    
    # Convertir a DataFrame para filtrar por fechas
    df_feed = pd.DataFrame(resultados_feed)
    
    # Filtrar por rango de fechas
    fecha_inicio_pd = pd.to_datetime(fecha_inicio)
    fecha_fin_pd = pd.to_datetime(fecha_fin)
    
    # Aplicar filtro de fechas (solo si hay fechas v√°lidas)
    if 'Fecha' in df_feed.columns:
        mascara_fechas = (df_feed['Fecha'] >= fecha_inicio_pd) & (df_feed['Fecha'] <= fecha_fin_pd)
        df_filtrado = df_feed[mascara_fechas]
    else:
        df_filtrado = df_feed
    
    st.info(f"üìä Encontrados {len(df_filtrado)} documentos del BOJA en el rango de fechas")
    
    # Si el feed RSS no tiene suficiente historia, intentar otros m√©todos
    if len(df_filtrado) == 0 and (fecha_fin_pd - fecha_inicio_pd).days > 30:
        st.warning("‚ö†Ô∏è El feed RSS solo contiene documentos recientes. Intentando m√©todo alternativo...")
        return buscar_boja_historico_profundo(fecha_inicio, fecha_fin, contenido_completo)
    
    # Convertir de vuelta a lista de diccionarios
    resultados = df_filtrado.to_dict('records')
    
    # Obtener contenido completo si se solicita
    if contenido_completo and len(resultados) > 0:
        progress_bar = st.progress(0)
        progress_text = st.empty()
        
        for idx, resultado in enumerate(resultados):
            progress_bar.progress((idx + 1) / len(resultados))
            progress_text.text(f"Extrayendo contenido {idx+1}/{len(resultados)}...")
            
            if resultado['Enlace']:
                resultado['Contenido_Completo'] = extraer_contenido_completo(resultado['Enlace'])
            
            time.sleep(0.3)
        
        progress_bar.empty()
        progress_text.empty()
    
    return resultados


def buscar_boja_historico_profundo(fecha_inicio, fecha_fin, contenido_completo=False):
    """B√∫squeda profunda para fechas antiguas (m√°s de 30 d√≠as)"""
    
    st.info("üîç B√∫squeda profunda activada para fechas antiguas...")
    
    resultados = []
    fecha_actual = fecha_inicio
    
    progress_text = st.empty()
    progress_bar = st.progress(0)
    
    total_dias = (fecha_fin - fecha_actual).days + 1
    dia_actual = 0
    
    while fecha_actual <= fecha_fin:
        progress_bar.progress(dia_actual / total_dias)
        progress_text.text(f"Consultando BOJA del {fecha_actual.strftime('%d/%m/%Y')} ({dia_actual+1}/{total_dias})")
        
        a√±o = fecha_actual.year
        
        # Calcular n√∫mero de bolet√≠n aproximado
        # El BOJA publica de lunes a viernes, aproximadamente 200-250 boletines/a√±o
        dia_a√±o = fecha_actual.timetuple().tm_yday
        
        # Calcular d√≠as h√°biles aproximados hasta la fecha
        dias_habiles_estimados = int((dia_a√±o / 365) * 200)
        
        # Probar un rango de n√∫meros de bolet√≠n alrededor del estimado
        for offset in range(-10, 11):
            num_boletin = max(1, min(250, dias_habiles_estimados + offset))
            
            # Probar diferentes formatos de URL
            urls_probar = [
                f"https://www.juntadeandalucia.es/boja/{a√±o}/{str(num_boletin).zfill(3)}/",
                f"https://www.juntadeandalucia.es/eboja/{a√±o}/{str(num_boletin).zfill(3)}/",
                f"https://www.juntadeandalucia.es/boja/{a√±o}/{str(num_boletin).zfill(3)}/index.html",
            ]
            
            boletin_encontrado = False
            
            for url in urls_probar:
                try:
                    response = session.get(url, timeout=10)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # Verificar que sea del d√≠a correcto
                        texto_pagina = soup.get_text()
                        fecha_str = fecha_actual.strftime('%d/%m/%Y')
                        
                        # Solo procesar si encuentra la fecha en la p√°gina
                        if fecha_str in texto_pagina or str(num_boletin) in texto_pagina:
                            # Buscar enlaces a disposiciones
                            for enlace in soup.find_all('a', href=True):
                                href = enlace['href']
                                titulo = enlace.get_text(strip=True)
                                
                                # Filtrar enlaces relevantes
                                if titulo and len(titulo) > 20:
                                    # Evitar enlaces de navegaci√≥n
                                    if any(x in href.lower() for x in ['javascript', 'mailto', '#', '/temas/', '/organismos/']):
                                        continue
                                    
                                    # Construir URL completa
                                    if href.startswith('/'):
                                        href_completo = f"https://www.juntadeandalucia.es{href}"
                                    elif not href.startswith('http'):
                                        base_url = url.rsplit('/', 1)[0]
                                        href_completo = f"{base_url}/{href}"
                                    else:
                                        href_completo = href
                                    
                                    # Evitar duplicados
                                    if not any(r['Enlace'] == href_completo for r in resultados):
                                        texto_completo = ""
                                        if contenido_completo:
                                            texto_completo = extraer_contenido_completo(href_completo)
                                        
                                        resultados.append({
                                            'Bolet√≠n': 'BOJA',
                                            'T√≠tulo': titulo,
                                            'Resumen': f'BOJA n√∫m. {num_boletin} del {fecha_actual.strftime("%d/%m/%Y")}',
                                            'Contenido_Completo': texto_completo,
                                            'Enlace': href_completo,
                                            'Fecha': pd.to_datetime(fecha_actual)
                                        })
                            
                            boletin_encontrado = True
                            break  # Salir del loop de URLs
                    
                    time.sleep(0.2)
                    
                except requests.exceptions.RequestException:
                    continue
                except Exception:
                    continue
            
            if boletin_encontrado:
                break  # Salir del loop de offsets
        
        fecha_actual += timedelta(days=1)
        dia_actual += 1
    
    progress_bar.empty()
    progress_text.empty()
    
    return resultados

# ============= FUNCI√ìN DE VERIFICACI√ìN DE CONSISTENCIA =============

def verificar_consistencia_busqueda():
    """Verifica que la b√∫squeda hist√≥rica devuelve los mismos resultados que el feed RSS"""
    
    st.subheader("üß™ Verificaci√≥n de Consistencia")
    st.write("Compara los resultados del Feed RSS vs B√∫squeda Hist√≥rica para las mismas fechas")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**1Ô∏è‚É£ Resultados del Feed RSS (√∫ltimos 7 d√≠as)**")
        
        with st.spinner("Obteniendo feed RSS..."):
            resultados_rss = buscar_boja_feed(contenido_completo=False)
            
            if resultados_rss:
                df_rss = pd.DataFrame(resultados_rss)
                
                # Filtrar √∫ltimos 7 d√≠as
                hace_7_dias = pd.to_datetime(datetime.now() - timedelta(days=7))
                df_rss_filtrado = df_rss[df_rss['Fecha'] >= hace_7_dias]
                
                st.metric("Documentos encontrados", len(df_rss_filtrado))
                
                if len(df_rss_filtrado) > 0:
                    st.dataframe(
                        df_rss_filtrado[['T√≠tulo', 'Fecha']].head(5),
                        use_container_width=True
                    )
            else:
                st.error("No se obtuvieron resultados del RSS")
    
    with col2:
        st.write("**2Ô∏è‚É£ Resultados de B√∫squeda Hist√≥rica (mismas fechas)**")
        
        with st.spinner("Obteniendo b√∫squeda hist√≥rica..."):
            fecha_inicio = datetime.now() - timedelta(days=7)
            fecha_fin = datetime.now()
            
            resultados_historico = buscar_boja_historico(
                fecha_inicio,
                fecha_fin,
                contenido_completo=False
            )
            
            if resultados_historico:
                df_historico = pd.DataFrame(resultados_historico)
                
                st.metric("Documentos encontrados", len(df_historico))
                
                if len(df_historico) > 0:
                    st.dataframe(
                        df_historico[['T√≠tulo', 'Fecha']].head(5),
                        use_container_width=True
                    )
            else:
                st.error("No se obtuvieron resultados del hist√≥rico")
    
    # Comparaci√≥n
    st.markdown("---")
    st.write("### üìä Comparaci√≥n de Resultados")
    
    if resultados_rss and resultados_historico:
        df_rss_filtrado = pd.DataFrame(resultados_rss)
        hace_7_dias = pd.to_datetime(datetime.now() - timedelta(days=7))
        df_rss_filtrado = df_rss_filtrado[df_rss_filtrado['Fecha'] >= hace_7_dias]
        
        df_historico = pd.DataFrame(resultados_historico)
        
        col_a, col_b, col_c = st.columns(3)
        
        with col_a:
            st.metric("Feed RSS", len(df_rss_filtrado))
        with col_b:
            st.metric("Hist√≥rico", len(df_historico))
        with col_c:
            diferencia = abs(len(df_rss_filtrado) - len(df_historico))
            st.metric("Diferencia", diferencia)
        
        if len(df_rss_filtrado) == len(df_historico):
            st.success(f"‚úÖ ¬°Perfecto! Ambos m√©todos devuelven el mismo n√∫mero de documentos: {len(df_rss_filtrado)}")
        else:
            st.warning(f"‚ö†Ô∏è Diferencia encontrada: RSS={len(df_rss_filtrado)}, Hist√≥rico={len(df_historico)}")
            
            # Mostrar documentos que est√°n en uno pero no en el otro
            enlaces_rss = set(df_rss_filtrado['Enlace'].tolist())
            enlaces_historico = set(df_historico['Enlace'].tolist())
            
            solo_rss = enlaces_rss - enlaces_historico
            solo_historico = enlaces_historico - enlaces_rss
            
            if solo_rss:
                with st.expander(f"üìÑ Solo en RSS: {len(solo_rss)} documentos"):
                    for enlace in list(solo_rss)[:5]:
                        doc = df_rss_filtrado[df_rss_filtrado['Enlace'] == enlace].iloc[0]
                        st.write(f"- {doc['T√≠tulo'][:80]}...")
            
            if solo_historico:
                with st.expander(f"üìÑ Solo en Hist√≥rico: {len(solo_historico)} documentos"):
                    for enlace in list(solo_historico)[:5]:
                        doc = df_historico[df_historico['Enlace'] == enlace].iloc[0]
                        st.write(f"- {doc['T√≠tulo'][:80]}...")

# ============= FUNCI√ìN DE DIAGN√ìSTICO =============

def diagnosticar_boja():
    """Funci√≥n de diagn√≥stico para detectar problemas de acceso al BOJA"""
    st.subheader("üîß Diagn√≥stico de Acceso al BOJA")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fecha_prueba = st.date_input(
            "Fecha para probar",
            datetime.now() - timedelta(days=7),
            max_value=datetime.now()
        )
    
    with col2:
        num_boletin = st.number_input(
            "N√∫mero de bolet√≠n (opcional)",
            min_value=1,
            max_value=300,
            value=100
        )
    
    if st.button("üöÄ Ejecutar diagn√≥stico", type="primary"):
        st.markdown("---")
        st.write("### Probando diferentes endpoints...")
        
        a√±o = fecha_prueba.year
        dia_a√±o = fecha_prueba.timetuple().tm_yday
        num_estimado = int((dia_a√±o / 365) * 250)
        
        # Lista de URLs a probar
        urls_prueba = [
            ("Feed RSS BOJA", "https://www.juntadeandalucia.es/boja/distribucion/boja.xml"),
            ("e-BOJA A√±o", f"https://www.juntadeandalucia.es/eboja/{a√±o}/"),
            ("BOJA Cl√°sico", f"https://www.juntadeandalucia.es/boja/{a√±o}/"),
            ("e-BOJA Bolet√≠n espec√≠fico", f"https://www.juntadeandalucia.es/eboja/{a√±o}/{str(num_boletin).zfill(3)}/"),
            ("BOJA Bolet√≠n estimado", f"https://www.juntadeandalucia.es/boja/{a√±o}/{str(num_estimado).zfill(3)}/index.html"),
            ("API Datos Abiertos", "https://www.juntadeandalucia.es/datosabiertos/portal/api/3/action/package_search?q=boja"),
            ("Buscador e-BOJA", "https://www.juntadeandalucia.es/eboja/static/index.html"),
        ]
        
        resultados_test = []
        
        for nombre, url in urls_prueba:
            try:
                with st.spinner(f"Probando: {nombre}..."):
                    response = session.get(url, timeout=15)
                    
                    resultado = {
                        "Endpoint": nombre,
                        "URL": url,
                        "Status": response.status_code,
                        "Tama√±o": f"{len(response.content)} bytes",
                        "Estado": "‚úÖ OK" if response.status_code == 200 else f"‚ùå Error {response.status_code}"
                    }
                    
                    resultados_test.append(resultado)
                    
                    # Mostrar informaci√≥n adicional para endpoints exitosos
                    if response.status_code == 200:
                        with st.expander(f"‚úÖ {nombre} - Ver detalles"):
                            st.code(response.text[:1000], language="html")
                            
                            # Intentar parsear contenido
                            soup = BeautifulSoup(response.text, 'html.parser')
                            enlaces = soup.find_all('a', href=True)
                            st.write(f"**Enlaces encontrados:** {len(enlaces)}")
                            
                            if len(enlaces) > 0:
                                st.write("**Primeros 5 enlaces:**")
                                for enlace in enlaces[:5]:
                                    st.write(f"- {enlace.get_text(strip=True)[:100]} ‚Üí {enlace['href'][:100]}")
                    else:
                        st.error(f"‚ùå {nombre} - Error {response.status_code}")
                
                time.sleep(0.5)
                
            except requests.exceptions.Timeout:
                resultados_test.append({
                    "Endpoint": nombre,
                    "URL": url,
                    "Status": "Timeout",
                    "Tama√±o": "N/A",
                    "Estado": "‚è±Ô∏è Timeout"
                })
                st.warning(f"‚è±Ô∏è {nombre} - Timeout")
            
            except Exception as e:
                resultados_test.append({
                    "Endpoint": nombre,
                    "URL": url,
                    "Status": "Error",
                    "Tama√±o": "N/A",
                    "Estado": f"üî¥ Error: {str(e)[:50]}"
                })
                st.error(f"üî¥ {nombre} - {str(e)[:100]}")
        
        # Mostrar tabla resumen
        st.markdown("---")
        st.write("### üìä Resumen de Diagn√≥stico")
        df_diagnostico = pd.DataFrame(resultados_test)
        st.dataframe(df_diagnostico, use_container_width=True)
        
        # Recomendaciones
        st.markdown("---")
        st.write("### üí° Recomendaciones")
        
        endpoints_ok = sum(1 for r in resultados_test if r["Status"] == 200)
        
        if endpoints_ok == 0:
            st.error("‚ùå No se pudo acceder a ning√∫n endpoint. Posibles causas:")
            st.write("- Problema de conexi√≥n a internet")
            st.write("- Firewall bloqueando el acceso")
            st.write("- Los servidores del BOJA est√°n temporalmente inaccesibles")
        elif endpoints_ok < 3:
            st.warning("‚ö†Ô∏è Acceso limitado. Algunas URLs funcionan, otras no.")
            st.write("- Usa solo los feeds que funcionan (BOJA Feed RSS)")
            st.write("- La b√∫squeda hist√≥rica puede no funcionar correctamente")
        else:
            st.success("‚úÖ La mayor√≠a de endpoints funcionan correctamente")
            st.write("- El sistema deber√≠a funcionar sin problemas")
            st.write("- Si la b√∫squeda hist√≥rica falla, puede ser por URLs antiguas")


def filtrar_resultados(df, palabras_clave, solo_ayudas=True, busqueda_exacta=False):
    """Filtra los resultados con regex mejorado"""
    if df.empty:
        return df
    
    if 'Contenido_Completo' in df.columns:
        df['_texto_busqueda'] = (
            df['T√≠tulo'].fillna('').astype(str) + ' ' + 
            df['Resumen'].fillna('').astype(str) + ' ' +
            df['Contenido_Completo'].fillna('').astype(str)
        )
    else:
        df['_texto_busqueda'] = (
            df['T√≠tulo'].fillna('').astype(str) + ' ' + 
            df['Resumen'].fillna('').astype(str)
        )
    
    if solo_ayudas:
        patron_ayudas = r'\b(ayuda|ayudas|subvenci√≥n|subvencion|subvenciones|convocatoria|convocatorias|bases\s+reguladoras)\b'
        mascara_ayudas = df['_texto_busqueda'].str.contains(
            patron_ayudas, 
            case=False, 
            regex=True, 
            na=False
        )
        df = df[mascara_ayudas]
    
    if palabras_clave:
        mascara_final = pd.Series([False] * len(df), index=df.index)
        
        for palabra in palabras_clave:
            palabra = palabra.strip()
            if palabra:
                if busqueda_exacta:
                    palabra_escaped = re.escape(palabra)
                    patron = r'\b' + palabra_escaped + r'\b'
                    mascara_palabra = df['_texto_busqueda'].str.contains(
                        patron, 
                        case=False, 
                        regex=True, 
                        na=False
                    )
                else:
                    mascara_palabra = df['_texto_busqueda'].str.contains(
                        palabra, 
                        case=False, 
                        regex=False, 
                        na=False
                    )
                
                mascara_final = mascara_final | mascara_palabra
        
        df = df[mascara_final]
    
    df = df.drop(columns=['_texto_busqueda'])
    
    if 'Contenido_Completo' in df.columns:
        df = df.drop(columns=['Contenido_Completo'])
    
    return df

# ============= INTERFAZ =============

st.title("üîç Buscador Inteligente de Ayudas y Subvenciones")
st.markdown("**BOJA** (Junta de Andaluc√≠a) + **BOE** (Estado) - Con IA de OpenAI")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n")
    
    # ============= MODO DIAGN√ìSTICO (AL PRINCIPIO) =============
    modo_diagnostico = st.checkbox("üîß Modo diagn√≥stico", value=False)
    
    if modo_diagnostico:
        st.markdown("---")
        diagnosticar_boja()
        st.markdown("---")
        
        if st.button("üß™ Verificar consistencia de b√∫squeda"):
            verificar_consistencia_busqueda()
        
        st.markdown("---")
    
    # ============= CONFIGURACI√ìN DE IA =============
    st.subheader("ü§ñ Inteligencia Artificial")
    
    usar_ia = st.checkbox(
        "Activar res√∫menes con IA",
        value=False,
        help="Genera res√∫menes autom√°ticos estructurados de cada ayuda"
    )
    
    api_key_openai = None
    modelo_openai = None
    
    if usar_ia:
        # Intentar cargar desde secrets, si no existe mostrar input
        api_key_default = ""
        try:
            api_key_default = st.secrets.get("openai", {}).get("api_key", "")
        except:
            pass
        
        if api_key_default:
            api_key_openai = api_key_default
            st.success("‚úÖ API Key cargada desde configuraci√≥n segura")
        else:
            api_key_openai = st.text_input(
                "üîë API Key de OpenAI:",
                type="password",
                help="Obt√©n tu API key en: https://platform.openai.com/api-keys"
            )
        
        if api_key_openai:
            modelo_openai = st.selectbox(
                "Modelo OpenAI:",
                ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
                help="gpt-4o-mini: $0.15/1M tokens (recomendado)\ngpt-4o: $2.50/1M tokens (m√°s potente)"
            )
            
            st.info(f"üí∞ Costo estimado por resumen: ~$0.001 con {modelo_openai}")
        else:
            st.warning("‚ö†Ô∏è Ingresa tu API Key de OpenAI para usar IA")
    
    # B√∫squeda inteligente
    st.markdown("---")
    busqueda_inteligente = st.checkbox(
        "üîÆ B√∫squeda inteligente con IA",
        value=False,
        help="Describe lo que buscas en lenguaje natural"
    )
    
    palabras_clave = ""
    
    if busqueda_inteligente and api_key_openai:
        consulta_natural = st.text_area(
            "Describe lo que buscas:",
            placeholder="Ejemplo: Busco ayudas para abrir un negocio de turismo rural en Andaluc√≠a con fondos europeos",
            height=100
        )
        
        if st.button("üîÆ Generar palabras clave", type="secondary"):
            if consulta_natural:
                with st.spinner("Analizando tu consulta con IA..."):
                    palabras_generadas = busqueda_inteligente_openai(
                        consulta_natural, 
                        api_key_openai, 
                        modelo_openai or "gpt-4o-mini"
                    )
                    st.success(f"‚úÖ Palabras clave: **{palabras_generadas}**")
                    palabras_clave = palabras_generadas
            else:
                st.warning("Escribe una consulta primero")
    
    st.markdown("---")
    
    # ============= FUENTES DE DATOS =============
    st.subheader("üì∞ Fuentes de datos")
    
    usar_boja = st.checkbox("BOJA (Feed del d√≠a)", value=True)
    usar_boe = st.checkbox("BOE (RSS del d√≠a)", value=True)
    
    st.markdown("**üìÖ B√∫squeda hist√≥rica**")
    usar_boja_hist = st.checkbox(
        "BOJA (Hist√≥rico por fechas)", 
        value=False,
        help="Busca en boletines anteriores (usa el feed RSS filtrado por fechas)"
    )
    usar_boe_hist = st.checkbox(
        "BOE (Hist√≥rico - API oficial)", 
        value=False,
        help="Busca usando la API oficial"
    )
    
    fecha_desde = None
    fecha_hasta = None
    
    if usar_boja_hist or usar_boe_hist:
        st.markdown("**Rango de fechas:**")
        col1, col2 = st.columns(2)
        
        fecha_desde = col1.date_input(
            "Desde",
            datetime.now() - timedelta(days=30),
            max_value=datetime.now()
        )
        
        fecha_hasta = col2.date_input(
            "Hasta",
            datetime.now(),
            max_value=datetime.now()
        )
        
        if fecha_desde > fecha_hasta:
            st.error("‚ö†Ô∏è La fecha 'Desde' debe ser anterior a 'Hasta'")
        
        dias_rango = (fecha_hasta - fecha_desde).days
        if dias_rango > 90:
            st.warning(f"‚è±Ô∏è Rango amplio ({dias_rango} d√≠as)")
    
    st.markdown("---")
    
    # ============= OPCIONES DE B√öSQUEDA =============
    st.subheader("üîç Opciones de b√∫squeda")
    
    contenido_completo = st.checkbox(
        "üî• Buscar en contenido completo",
        value=False,
        help="‚ö†Ô∏è MUY LENTO: Descarga y analiza el texto completo"
    )
    
    if contenido_completo:
        st.warning("‚è±Ô∏è Puede tardar 5-10 minutos o m√°s")
    
    st.markdown("---")
    
    # ============= FILTROS =============
    st.subheader("üéØ Filtros")
    solo_ayudas = st.checkbox("Solo ayudas/subvenciones", value=True)
    
    if not busqueda_inteligente:
        palabras_clave = st.text_input(
            "Palabras clave (separadas por coma)", 
            "",
            help="Ejemplo: feder, turismo, pyme"
        )
    
    busqueda_exacta = st.checkbox(
        "B√∫squeda de palabra exacta",
        value=True,
        help="'feder' no encuentra 'confederaci√≥n'"
    )

# ============= BOT√ìN DE B√öSQUEDA =============
if st.button("üöÄ Buscar", type="primary"):
    if (usar_boja_hist or usar_boe_hist) and fecha_desde and fecha_hasta and fecha_desde > fecha_hasta:
        st.error("‚ùå Corrige el rango de fechas")
    else:
        with st.spinner("Buscando en boletines oficiales..."):
            todos_resultados = []
            
            if usar_boja:
                with st.status("üîé Buscando en BOJA (feed reciente)..."):
                    todos_resultados.extend(buscar_boja_feed(contenido_completo))
            
            if usar_boe:
                with st.status("üîé Buscando en BOE (RSS reciente)..."):
                    todos_resultados.extend(buscar_boe_rss(contenido_completo))
            
            if usar_boja_hist and fecha_desde and fecha_hasta:
                with st.status(f"üîé Buscando en BOJA hist√≥rico..."):
                    todos_resultados.extend(
                        buscar_boja_historico(
                            datetime.combine(fecha_desde, datetime.min.time()),
                            datetime.combine(fecha_hasta, datetime.min.time()),
                            contenido_completo
                        )
                    )
            
            if usar_boe_hist and fecha_desde and fecha_hasta:
                with st.status(f"üîé Consultando BOE hist√≥rico..."):
                    todos_resultados.extend(
                        buscar_boe_historico_api(
                            datetime.combine(fecha_desde, datetime.min.time()),
                            datetime.combine(fecha_hasta, datetime.min.time()),
                            contenido_completo
                        )
                    )
            
            # Procesar resultados
            if todos_resultados:
                df = pd.DataFrame(todos_resultados)
                df = df.drop_duplicates(subset=['Enlace'], keep='first')
                
                lista_palabras = [p.strip() for p in palabras_clave.split(',') if p.strip()]
                df_filtrado = filtrar_resultados(df, lista_palabras, solo_ayudas, busqueda_exacta)
                df_filtrado = df_filtrado.sort_values('Fecha', ascending=False, na_position='last')
                
                if len(df_filtrado) > 0:
                    st.success(f"‚úÖ **{len(df_filtrado)} resultados** encontrados (de {len(df)} totales)")
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("Total resultados", len(df_filtrado))
                    col2.metric("BOJA", len(df_filtrado[df_filtrado['Bolet√≠n'] == 'BOJA']))
                    col3.metric("BOE", len(df_filtrado[df_filtrado['Bolet√≠n'] == 'BOE']))
                    
                    # ============= RES√öMENES CON IA =============
                    if usar_ia and api_key_openai:
                        st.markdown("---")
                        st.subheader("ü§ñ Res√∫menes generados con IA")
                        
                        max_resumenes = st.slider(
                            "N√∫mero de ayudas a resumir:",
                            min_value=1,
                            max_value=min(20, len(df_filtrado)),
                            value=min(5, len(df_filtrado)),
                            help="Cada resumen tarda ~2-5 segundos"
                        )
                        
                        if st.button("üìù Generar res√∫menes con IA", type="primary"):
                            resumenes = []
                            progress_bar = st.progress(0)
                            progress_text = st.empty()
                            
                            for idx, (_, row) in enumerate(df_filtrado.head(max_resumenes).iterrows()):
                                progress_bar.progress((idx + 1) / max_resumenes)
                                progress_text.text(f"Resumiendo {idx+1}/{max_resumenes}: {row['T√≠tulo'][:50]}...")
                                
                                texto_completo = row.get('Contenido_Completo', '')
                                if not texto_completo and row['Enlace']:
                                    texto_completo = extraer_contenido_completo(row['Enlace'])
                                
                                texto_para_ia = f"{row['T√≠tulo']}\n\n{row['Resumen']}\n\n{texto_completo[:6000]}"
                                
                                resumen_ia = resumir_con_openai(
                                    texto_para_ia, 
                                    api_key_openai, 
                                    modelo_openai
                                )
                                
                                resumenes.append({
                                    **row.to_dict(),
                                    **resumen_ia
                                })
                            
                            progress_bar.empty()
                            progress_text.empty()
                            
                            # Mostrar res√∫menes
                            for res in resumenes:
                                with st.expander(f"üìÑ {res['T√≠tulo'][:100]}...", expanded=False):
                                    col1, col2 = st.columns([2, 1])
                                    
                                    with col1:
                                        st.markdown(f"**üéØ Tipo:** {res.get('tipo', 'N/A')}")
                                        st.markdown(f"**üë• Beneficiarios:** {res.get('beneficiarios', 'N/A')}")
                                        st.markdown(f"**üí∞ Cuant√≠a:** {res.get('cuantia', 'N/A')}")
                                        st.markdown(f"**üìÖ Plazo:** {res.get('plazo', 'N/A')}")
                                    
                                    with col2:
                                        st.markdown(f"**üì∞ Bolet√≠n:** {res['Bolet√≠n']}")
                                        if pd.notna(res.get('Fecha')):
                                            st.markdown(f"**üìÜ Fecha:** {res['Fecha'].strftime('%d/%m/%Y')}")
                                        st.markdown(f"[üîó Ver documento]({res['Enlace']})")
                                    
                                    st.markdown("---")
                                    st.markdown(f"**üìù Resumen IA:**")
                                    st.info(res.get('resumen', 'No disponible'))
                            
                            # Exportar
                            df_resumenes = pd.DataFrame(resumenes)
                            columnas_export = ['Bolet√≠n', 'T√≠tulo', 'tipo', 'beneficiarios', 'cuantia', 'plazo', 'resumen', 'Enlace', 'Fecha']
                            columnas_disponibles = [col for col in columnas_export if col in df_resumenes.columns]
                            
                            csv_resumenes = df_resumenes[columnas_disponibles].to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                "üì• Descargar res√∫menes con IA (CSV)",
                                csv_resumenes,
                                f"resumenes_ia_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                                "text/csv",
                                key='download-resumenes'
                            )
                    
                    # Tabla original
                    st.markdown("---")
                    st.subheader("üìä Tabla de resultados")
                    st.dataframe(
                        df_filtrado,
                        use_container_width=True,
                        height=600,
                        column_config={
                            "Enlace": st.column_config.LinkColumn("Enlace"),
                            "Fecha": st.column_config.DatetimeColumn("Fecha", format="DD/MM/YYYY")
                        }
                    )
                    
                    csv = df_filtrado.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        "üì• Descargar CSV",
                        csv,
                        f"ayudas_subvenciones_{datetime.now().strftime('%Y%m%d')}.csv",
                        "text/csv",
                        key='download-csv'
                    )
                else:
                    st.warning("‚ö†Ô∏è No se encontraron resultados")
                    st.info("üí° **Sugerencias:**\n- Desactiva 'Solo ayudas/subvenciones'\n- Reduce palabras clave\n- Cambia a b√∫squeda no exacta\n- Ampl√≠a el rango de fechas")
            else:
                st.error("‚ùå No se obtuvieron resultados")

# ============= INFORMACI√ìN =============
with st.expander("‚ÑπÔ∏è Ayuda y Gu√≠a de Uso"):
    st.markdown("""
    ### üéØ C√≥mo usar esta aplicaci√≥n
    
    #### 1. Configurar OpenAI (opcional pero recomendado)
    - Obt√©n tu API Key en: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
    - P√©gala en el campo "API Key de OpenAI"
    - Esto activar√° res√∫menes inteligentes y b√∫squeda en lenguaje natural
    
    #### 2. Seleccionar fuentes
    - **Feed del d√≠a**: Publicaciones m√°s recientes (r√°pido)
    - **Hist√≥rico**: Busca en fechas anteriores usando el mismo feed RSS
    
    #### 3. B√∫squeda inteligente con IA
    - Activa "B√∫squeda inteligente con IA"
    - Describe en lenguaje natural lo que buscas
    - Ejemplo: "Busco financiaci√≥n para startups tecnol√≥gicas en Andaluc√≠a"
    - La IA convertir√° tu consulta en palabras clave √≥ptimas
    
    #### 4. B√∫squeda tradicional (sin IA)
    - Introduce palabras clave separadas por comas
    - Ejemplo: "feder, turismo, pyme"
    - Activa "b√∫squeda exacta" para mayor precisi√≥n
    
    #### 5. Generar res√∫menes con IA
    - Despu√©s de buscar, activa "Generar res√∫menes con IA"
    - Selecciona cu√°ntas ayudas resumir (m√°x. 20)
    - La IA extraer√°: tipo, beneficiarios, cuant√≠a, plazo y resumen
    
    #### 6. Modo diagn√≥stico
    - Activa "Modo diagn√≥stico" en el sidebar
    - Prueba diferentes endpoints del BOJA
    - Verifica consistencia entre Feed RSS e Hist√≥rico
    - Identifica qu√© URLs funcionan y cu√°les no
    
    ### ‚úÖ Mejoras en esta versi√≥n
    
    - **B√∫squeda hist√≥rica mejorada**: Usa el feed RSS y filtra por fechas
    - **Feed RSS e Hist√≥rico devuelven los mismos resultados** para fechas recientes
    - **Filtrado de p√°ginas institucionales**: Solo muestra documentos oficiales
    - **Verificaci√≥n de consistencia**: Compara ambos m√©todos
    
    ### üí∞ Costos de OpenAI
    
    - **gpt-4o-mini**: ~$0.001 por resumen (recomendado)
    - **gpt-4o**: ~$0.003 por resumen (m√°s potente)
    - Resumir 10 ayudas: ~$0.01-0.03 USD
    
    ### üîç Tipos de b√∫squeda
    
    **Exacta** (activada):
    - "feder" encuentra: "FEDER", "Feder"
    - NO encuentra: "federaci√≥n", "confederaci√≥n"
    
    **Normal** (desactivada):
    - "feder" encuentra todo lo anterior
    
    ### üìä Fuentes oficiales
    
    - **BOJA**: [https://www.juntadeandalucia.es/boja](https://www.juntadeandalucia.es/boja)
    - **BOE**: [https://www.boe.es](https://www.boe.es)
    - **API BOE**: [https://www.boe.es/datosabiertos/](https://www.boe.es/datosabiertos/)
    
    ### üîß Soluci√≥n de problemas
    
    Si la b√∫squeda hist√≥rica no devuelve los mismos resultados:
    1. Activa el "Modo diagn√≥stico"
    2. Ejecuta "Verificar consistencia de b√∫squeda"
    3. Compara los resultados de ambos m√©todos
    4. El feed RSS tiene documentos de ~30 d√≠as hacia atr√°s
    """)

# Footer
st.markdown("---")
st.markdown("ü§ñ **Desarrollado con Streamlit + OpenAI** | üìÖ Actualizado: Octubre 2025")
st.markdown("üîß **Versi√≥n 2.0 mejorada** | Feed RSS e Hist√≥rico ahora devuelven los mismos resultados ‚úÖ")
